{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4313, 100, 1000)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "b = np.load(r\"C:\\Users\\20143\\data_label.npy\")\n",
    "a = np.load(r\"C:\\Users\\20143\\data.npy\")\n",
    "X, Y = shuffle(a, b)\n",
    "print(type(X))\n",
    "X.shape\n",
    "\n",
    "#1000列[]\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# train_x,test_x,train_y,test_y= train_test_split(X,Y, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "list_=[0 for x in range(0,1000)]\n",
    "for i in X:\n",
    "#     print(i.shape)\n",
    "    s=[0 for x in range(0,1000)]\n",
    "    count=0\n",
    "#     print(type(i[0,:]))\n",
    "#     print(i[0,:].shape)\n",
    "#     print(i[0,:].tolist())\n",
    "    for j in i[0,:].tolist():\n",
    "#         print(j)\n",
    "#         break\n",
    "        if j==0.0:\n",
    "            pass\n",
    "        else:\n",
    "            s[count]=1\n",
    "        count=count+1\n",
    "    data.append(s)\n",
    "#     break\n",
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4313, 1000)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "train_x,test_x,train_y,test_y= train_test_split(data,Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 2, 3, 7, 8, 2, 3, 8, 5, 0, 0, 2, 0, 5, 1, 4, 1, 6, 4,\n",
       "       0, 0, 8, 2, 0, 5, 0, 0, 2, 2, 2, 5, 5, 5, 2, 3, 5, 3, 0, 5, 3, 0,\n",
       "       3, 1, 0, 0, 5, 1, 0, 6, 3, 3, 0, 2, 5, 0, 5, 0, 5, 0, 1, 5, 2, 1,\n",
       "       2, 2, 4, 0, 0, 0, 5, 5, 0, 3, 2, 2, 5, 5, 0, 4, 8, 7, 3, 0, 1, 0,\n",
       "       4, 3, 0, 0, 2, 2, 1, 0, 5, 5, 0, 0, 6, 2, 5, 5, 5, 0, 5, 0, 0, 0,\n",
       "       5, 3, 5, 8, 0, 0, 0, 7, 3, 2, 5, 0, 5, 2, 5, 5, 0, 5, 5, 0, 0, 5,\n",
       "       5, 5, 8, 5, 2, 0, 0, 3, 5, 4, 3, 5, 2, 5, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 2, 5, 8, 0, 0, 6, 5, 4, 6, 5, 3, 1, 5, 5, 0, 5, 6, 0, 0, 5, 5,\n",
       "       6, 0, 0, 2, 1, 6, 0, 4, 5, 0, 1, 0, 5, 2, 5, 1, 2, 1, 2, 5, 0, 8,\n",
       "       5, 3, 5, 8, 2, 0, 6, 0, 0, 1, 0, 0, 0, 2, 7, 0, 8, 5, 4, 0, 2, 5,\n",
       "       8, 2, 5, 5, 4, 5, 4, 8, 0, 5, 0, 5, 0, 0, 5, 2, 5, 4, 5, 2, 0, 0,\n",
       "       0, 0, 0, 6, 5, 1, 7, 1, 0, 0, 5, 4, 0, 5, 0, 1, 0, 2, 1, 5, 6, 0,\n",
       "       1, 0, 0, 2, 5, 1, 0, 0, 2, 2, 8, 4, 5, 3, 0, 6, 0, 1, 5, 0, 5, 0,\n",
       "       0, 1, 0, 2, 5, 8, 8, 5, 4, 5, 3, 5, 3, 4, 0, 5, 2, 5, 0, 5, 3, 8,\n",
       "       5, 3, 0, 3, 5, 8, 5, 2, 5, 5, 0, 0, 4, 2, 8, 0, 8, 2, 0, 0, 3, 5,\n",
       "       5, 5, 0, 2, 2, 0, 2, 5, 2, 0, 2, 6, 6, 2, 8, 0, 0, 0, 0, 0, 2, 1,\n",
       "       0, 5, 5, 1, 5, 0, 2, 0, 0, 1, 3, 0, 8, 0, 3, 1, 3, 1, 0, 5, 2, 6,\n",
       "       0, 0, 2, 5, 5, 0, 0, 3, 1, 0, 0, 2, 0, 0, 5, 0, 2, 0, 1, 4, 3, 0,\n",
       "       1, 2, 5, 2, 5, 0, 0, 8, 5, 5, 0, 1, 0, 0, 4, 0, 0, 0, 6, 0, 2, 0,\n",
       "       6, 0, 0, 0, 1, 2, 3, 0, 0, 8, 4, 3, 5, 5])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN准确率:0.2894\n",
      "0.286561550506443\n",
      "0.28935185185185186\n",
      "0.27151697853576773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM准确率:0.3333\n",
      "0.1111111111111111\n",
      "0.3333333333333333\n",
      "0.16666666666666666\n",
      "多项式朴素贝叶斯准确率:0.3426\n",
      "0.31871371509345064\n",
      "0.3425925925925926\n",
      "0.3185574379519077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cart决策树准确率:0.2963\n",
      "0.29392894045076184\n",
      "0.2962962962962963\n",
      "0.2938746169547712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "#读取数据，数据采用sklearn自带的数据集\n",
    "# digits=load_digits()\n",
    "# data=digits.data\n",
    "\n",
    "\n",
    "# y_test = to_categorical(y_test)\n",
    "#分割数据，数据集中25%作为测试数据，其余作为训练数据\n",
    "# train_x,test_x,train_y,test_y=train_test_split(data,digits.target,test_size=0.1,random_state=1)\n",
    "#采用z-score规范化\n",
    "# ss=preprocessing.StandardScaler()\n",
    "# train_ss_x=ss.fit_transform(train_x)\n",
    "# test_ss_x=ss.transform(test_x)\n",
    "train_ss_x=train_x\n",
    "test_ss_x=test_x\n",
    "#创建KNN分类器\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(train_ss_x,train_y)\n",
    "#预测结果并输出\n",
    "predict_y=knn.predict(test_ss_x)\n",
    "print('KNN准确率:{:.4f}'.format(accuracy_score(test_y,predict_y)))\n",
    "# print(predict_y)\n",
    "# print(precision_score(test_y,predict_y, average=\"micro\"))\n",
    "# print(precision_score(test_y,predict_y, average=\"macro\"))\n",
    "#数据均衡情况macro\n",
    "print(precision_score(test_y,predict_y, average=\"weighted\"))\n",
    "#数据加权weighted\n",
    "#https://www.cnblogs.com/danny92/p/10675897.html\n",
    "\n",
    "print(recall_score(test_y,predict_y, average=\"weighted\"))\n",
    "print(f1_score(test_y,predict_y, average=\"weighted\"))\n",
    "#创建SVM分类器\n",
    "svm=SVC()\n",
    "svm.fit(train_ss_x,train_y)\n",
    "predict_y=svm.predict(test_ss_x)\n",
    "print('SVM准确率:{:.4f}'.format(accuracy_score(predict_y,test_y)))\n",
    "print(precision_score(test_y,predict_y, average=\"weighted\"))\n",
    "print(recall_score(test_y,predict_y, average=\"weighted\"))\n",
    "print(f1_score(test_y,predict_y, average=\"weighted\"))\n",
    "#采用Min-Max规范化\n",
    "mm=preprocessing.MinMaxScaler()\n",
    "train_mm_x=mm.fit_transform(train_x)\n",
    "test_mm_x=mm.transform(test_x)\n",
    "#创建朴素贝叶斯分类器\n",
    "mnb=MultinomialNB()\n",
    "mnb.fit(train_mm_x,train_y)\n",
    "predict_y=mnb.predict(test_mm_x)\n",
    "print('多项式朴素贝叶斯准确率:{:.4f}'.format(accuracy_score(predict_y,test_y)))\n",
    "print(precision_score(test_y,predict_y, average=\"weighted\" ))\n",
    "print(recall_score(test_y,predict_y, average=\"weighted\"))\n",
    "print(f1_score(test_y,predict_y, average=\"weighted\"))\n",
    "#创建cart决策树分类器\n",
    "dtc=DecisionTreeClassifier()\n",
    "dtc.fit(train_ss_x,train_y)\n",
    "predict_y=dtc.predict(test_ss_x)\n",
    "print('cart决策树准确率:{:.4f}'.format(accuracy_score(predict_y,test_y)))\n",
    "print(precision_score(test_y,predict_y, average=\"weighted\"))\n",
    "print(recall_score(test_y,predict_y, average=\"weighted\"))\n",
    "print(f1_score(test_y,predict_y, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面没有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 检查版本\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: {}'.format(numpy.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "\n",
    "\n",
    "# 导入数据、模块\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "mpl.rcParams['font.sans-serif']=['SimHei']\n",
    "\n",
    "# 训练集、验证集数据分割\n",
    "seed = 1729140713\n",
    "train,test,train_label,test_label = train_test_split(iris.data,iris.target,test_size = 0.3,random_state = seed)\n",
    "\n",
    "\n",
    "# 选用机器学习算法\n",
    "models = []\n",
    "models.append(('决策树', DecisionTreeClassifier()))\n",
    "models.append(('朴素贝叶斯', GaussianNB()))\n",
    "models.append(('随机森林', RandomForestClassifier()))\n",
    "models.append(('支持向量机SVM', SVC()))\n",
    "\n",
    "\n",
    "# 基于test集的预测及验证\n",
    "for name, model in models:\n",
    "    model.fit(train, train_label)\n",
    "    pre = model.predict(test)\n",
    "    results = model.score(test, test_label)\n",
    "    print(\"算法:{}\\n准确率:{}{} \".format(name,results*100,\"%\"))\n",
    "    print(classification_report(test_label,pre,target_names = iris.target_names))\n",
    "\n",
    "\n",
    "\n",
    "# 交叉验证\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state = seed)\n",
    "names=[]\n",
    "scores=[]\n",
    "for name, model in models:\n",
    "    cfit = model.fit(X_train, Y_train)\n",
    "    cfit.score(X_test, Y_test)\n",
    "    cv_scores = cross_val_score(model, X_train, Y_train, cv=10)\n",
    "    scores.append(cv_scores)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_scores.mean(), cv_scores.std())\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "# 算法比较\n",
    "fig = plt.figure()\n",
    "fig.suptitle('四种算法预测准确率比较图')\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.ylabel('算法')\n",
    "plt.xlabel('准确率')\n",
    "plt.boxplot(scores,vert=False,patch_artist=True,meanline=False,showmeans=True)\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#读取数据，数据采用sklearn自带的数据集\n",
    "digits=load_digits()\n",
    "data=digits.data\n",
    "\n",
    "# y_test = to_categorical(y_test)\n",
    "#分割数据，数据集中25%作为测试数据，其余作为训练数据\n",
    "train_x,test_x,train_y,test_y=train_test_split(data,digits.target,test_size=0.1,random_state=1)\n",
    "#采用z-score规范化\n",
    "ss=preprocessing.StandardScaler()\n",
    "train_ss_x=ss.fit_transform(train_x)\n",
    "test_ss_x=ss.transform(test_x)\n",
    "#创建KNN分类器\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(train_ss_x,train_y)\n",
    "#预测结果并输出\n",
    "predict_y=knn.predict(test_ss_x)\n",
    "print('KNN准确率:{:.4f}'.format(accuracy_score(predict_y,test_y)))\n",
    "#创建SVM分类器\n",
    "svm=SVC()\n",
    "svm.fit(train_ss_x,train_y)\n",
    "predict_y=svm.predict(test_ss_x)\n",
    "print('SVM准确率:{:.4f}'.format(accuracy_score(predict_y,test_y)))\n",
    "#采用Min-Max规范化\n",
    "mm=preprocessing.MinMaxScaler()\n",
    "train_mm_x=mm.fit_transform(train_x)\n",
    "test_mm_x=mm.transform(test_x)\n",
    "#创建朴素贝叶斯分类器\n",
    "mnb=MultinomialNB()\n",
    "mnb.fit(train_mm_x,train_y)\n",
    "predict_y=mnb.predict(test_mm_x)\n",
    "print('多项式朴素贝叶斯准确率:{:.4f}'.format(accuracy_score(predict_y,test_y)))\n",
    "#创建cart决策树分类器\n",
    "dtc=DecisionTreeClassifier()\n",
    "dtc.fit(train_ss_x,train_y)\n",
    "predict_y=dtc.predict(test_ss_x)\n",
    "print('cart决策树准确率:{:.4f}'.format(accuracy_score(predict_y,test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "X = np.array([[1,2],\n",
    "             [5,8],\n",
    "             [1.5,1.8],\n",
    "             [8,8],\n",
    "             [1,0.6],\n",
    "             [9,11],\n",
    "             [0,0],\n",
    "             [0,1],\n",
    "             [1,0]])\n",
    "y = [0,1,0,1,0,1,2,2,2]\n",
    "clf = svm.SVC(kernel='linear', C = 1.0)\n",
    "clf.fit(X,y)\n",
    "# clf = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
    "# clf.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([0.58,0.76]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    " decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n",
    " max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    " tol=0.001, verbose=False)\n",
    "dec = clf.decision_function([[1]])\n",
    "dec.shape[1] # 4 classes: 4*3/2 = 6\n",
    "\n",
    "clf.decision_function_shape = \"ovr\"\n",
    "dec = clf.decision_function([[1]])\n",
    "dec.shape[1] # 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c0f10157cf38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Consumer_complaint_narrative'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Product'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mcount_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX_train_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Consumer_complaint_narrative'], df['Product'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-60c45f77d116>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m  \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m  \u001b[0maccuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m  \u001b[1;32mfor\u001b[0m \u001b[0mfold_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m    \u001b[0mentries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "models = [\n",
    "   RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "   LinearSVC(),\n",
    "   MultinomialNB(),\n",
    "   LogisticRegression(random_state=0),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    " model_name = model.__class__.__name__\n",
    " accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    " for fold_idx, accuracy in enumerate(accuracies):\n",
    "   entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "import seaborn as sns\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "             size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "cv_df.groupby('model_name').accuracy.mean()\n",
    "# model_name\n",
    "# LinearSVC: 0.822890\n",
    "# LogisticRegression: 0.792927\n",
    "# MultinomialNB: 0.688519\n",
    "# RandomForestClassifier: 0.443826\n",
    "# Name: accuracy, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
